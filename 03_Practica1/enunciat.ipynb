{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pràctica 1 - El procés de l'aprenentatge automàtic:\n",
    "Fins ara hem treballat amb problemes de classificació de conjunts que tenien 2 classes i que estaven generats de manera artificial. En aquesta pràctica començarem a fer feina amb conjunts de dades reals que a més tenen més d'una classe.\n",
    "\n",
    "El procés d'aplicar tècniques d'aprenentatge és un procés que consta de cinc parts:\n",
    "\n",
    "- **Tractament de les dades: preparació del conjunt de dades, selecció de característiques, obtenció dels conjunts d'entrenament / test**.\n",
    "\n",
    "- **Selecció de la / les mètriques adients**.\n",
    "\n",
    "- **Selecció de la tècnica d'aprenentatge automàtic**.\n",
    "\n",
    "- **Avaluació del model**.\n",
    "\n",
    "- **Ajustament del model**.\n",
    "\n",
    "## Tractament de dades: selecció de característiques\n",
    "\n",
    "## Separació del conjunt de dades: validació creuada per avaluar el rendiment del nostre model\n",
    "\n",
    "### Mètode _holdout_\n",
    "\n",
    "Aquest mètode consisteix a separar el conjunt de dades en tres subconjunts diferents: entrenament, validació i _test_. El conjunt d'entrenament s'usa com és habitual, és a dir per entrenar els diferents models. El conjunt de validació s'usa per seleccionar el millor dels models. El conjunt de _test_, que no usem en cap cas durant el procés d'entrenament, ens servirà per obtenir una idea poc esbiaixada de la capacitat del model d'adaptar-se a noves mostres, sobre aquest conjunt de dades serà sobre el qual obtindrem les mètriques finals del model.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "![](imatges/holdout.png)\n",
    "\n",
    "Aquest mètode encara que senzill d'emprar té un desavantatge, el rendiment del model depèn de com hem fet la partició de les dades.\n",
    "\n",
    "### Mètode _K-Fold_\n",
    "\n",
    "Aquesta tècnica és més robusta, ja que repetim el mètode anterior _k_ vegades en _k_ subconjunts del conjunt d'entrenament, per tant, obtenim _k_ models i el mateix nombre de mesures de rendiment. El resultat final s'obtè amb la mitjana de cada una de les repeticions realitzades, d'aquesta manera els resultats depenen manco de les particions que realitzem.\n",
    "\n",
    "Aquesta tècnica normalment s'usa per obtenir els millors paràmetres del model a aplicar, es a dir trobar aquells paràmetres que maximitzen el rendiment de la mètrica que volem usar. Un cop que tenim els millors paràmetres, reentrenam el model emprant el conjunt d'entrenament complet i obtenim les mètriques amb el conjunt de _test_.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "<img src=\"imatges/Kfold.png\" alt=\"kfold\" width=\"600\"/>\n",
    "\n",
    "La pregunta que ens podem fer és: Com seleccionar aquest paràmetre _k_ de forma correcta?\n",
    "\n",
    "Finalment, existeix una variant d'aquesta tècnica anomenada _stratified k-fold_ en el que les proporcions entre classes es mantenen a cada una de les iteracions, això és important quan tenim problemes desbalancejats.\n",
    "\n",
    "## Selecció de mètriques\n",
    "\n",
    "Un cop entrenat el nostre model, tenim la necessitat d'avaluar els resultats obtinguts amb aquest amb alguna mesura que sigui objectiva. Les mesures que explicarem en aquesta secció es calculen a partir d'una matriu de confusió que ens permet guardar quatre mesures bàsiques a partir de considerar que una de les classes és la positiva i l'altra és la negativa.\n",
    "\n",
    "- _True Positives_ (TP): L'algorisme classifica una mostra de la classe positiva com a membre de la classe positiva.\n",
    "- _True Negatives_ (TN): L'algorisme classifica una mostra de la classe negativa com a membre de la classe negativa.\n",
    "- _False Positives_ (FP): L'algorisme classifica una mostra de la classe negativa com a membre de la classe positiva.\n",
    "- _False Negatives_ (FN): L'algorisme classifica una mostra de la classe positiva com a membre de la classe negativa.\n",
    "\n",
    "Podem observar la matriu de confusió en el següent esquema:\n",
    "\n",
    "![image](imatges/confusion_matrix.png \"font: Python Machine Learning\")\n",
    "\n",
    "Aquesta matriu es pot obtenir de manera senzilla usant la funció `confusion_matrix` de la llibreria [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion%20matrix#sklearn-metrics-confusion-matrix)\n",
    "i es pot visualitzar amb la funció [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html?highlight=confusion%20matrix#sklearn-metrics-confusionmatrixdisplay)\n",
    "\n",
    "A partir d'aquestes mesures de primer ordre en podem treure d'altres més completes com l'error o l'exactitud, també es coneix amb el nom de _Accuracy_.\n",
    "\n",
    "$$ Error = \\frac{FP+FN}{FP+FN+TP+TN}$$\n",
    "<br>\n",
    "$$ Exactitut = \\frac{TP+TN}{FP+FN+TP+TN} = 1 - Error$$\n",
    "\n",
    "Per altra banda, tenim les mesures Rati de Vertaders Positius (_True Positive Rate_, TPR) i la Ratio de Falsos Positius (_False Positive Rate_, FPR) que estan dissenyades per problemes on hi ha una classe amb més mostres que l'altra:\n",
    "\n",
    "$$ FPR = \\frac{FP}{N} = \\frac{FP}{FP+TN} $$\n",
    "<br>\n",
    "$$ TPR = \\frac{TP}{P} = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Finalment, parlarem de precisió (_precision_) i la sensibilitat (_recall_) relacionades amb les ratios de vertaders positius i vertaders negatius:\n",
    "\n",
    "$$ Precisio = \\frac{TP}{TP+FP}$$\n",
    "<br>\n",
    " $$ Sensibilitat = TPR = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Tenim una mesura que engloba aquestes mesures anteriors:\n",
    "\n",
    "$$ F1 = 2 \\frac{Precisio \\times Sensibilitat}{Precisio + Sensibilitat}$$\n",
    "\n",
    "Per sort tenim un mòdul anomenat [_metrics_](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) on hi ha totes aquestes (i d'altres) mètriques ja implementades.\n",
    "\n",
    "### Qué passa si tenim més de dues classes?\n",
    "\n",
    "Podem generalitzar el que ja sabem per a dues classes a problemes amb tres o més classes, fixem-nos en la imatge següent:\n",
    "\n",
    "![image](imatges/confusion_matrix_multi.png \"font: Researchgate\")\n",
    "\n",
    "Una de les funcions que poden ser més pràctiques en casos multi-classe serà el [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report).\n",
    "\n",
    "## Un exemple complet\n",
    "\n",
    "A continuació teniu un exemple que resumeix el procés sencer emprant la llibreria `Scikit-learn`:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
